# ArUco Pen Pose â€” sistema penna+marker ArUco con trigger BLE e stima di posa

Sistema hardware/software per acquisire foto sincronizzate dal PC tramite trigger BLE inviato da un **ESP32** integrato in una **penna 3D** con un piccolo **cubo** stampato in 3D che monta **3/4 marker ArUco**.  
Il PC, alla ricezione dellâ€™input, scatta la foto (es. da camera industriale tipo Basler o webcam), **stima la posa della punta** della penna e la espone per uso realâ€‘time o per logging. In roadmap Ã¨ prevista la **replicazione della posa** con un **braccio robotico**.

---

## âœ¨ TL;DR

- **Hardware**: penna 3D + cubo con marker ArUco + ESP32 (BLE) + pulsanti.  
- **ESP32**: invia trigger BLE â†’ PC.  
- **PC App**: riceve trigger â†’ scatta foto â†’ detect ArUco â†’ `solvePnP` â†’ calcola posa della **punta** (offset noto dal cubo).  
- **Output**: posa in `camera_frame` + conversione opzionale in `world/robot_frame`.  
- **Roadmap**: streaming continuo, calibrazione semplificata, integrazione robot.

---

## ğŸ§± Architettura

1. **Utente preme un tasto** sulla penna (ESP32).
2. **ESP32 pubblica un evento BLE** (notifica/char write).
3. **PC Listener BLE** riceve lâ€™evento â†’ **trigga** la cattura immagine.
4. **PC Vision**:
   - Detect **ArUco** (dictionary configurabile).
   - Ricostruisce la posa del **cubo** con `cv::solvePnP`.
   - Applica la **trasformazione rigida** nota dal centro del cubo alla **punta** della penna.
5. **Output**: posizione/orientamento punta + timestamp + immagine (opzionale).
6. **(Futuro)** Invio posa al **controller del braccio robotico**.

---

## ğŸ§© Bill of Materials (BoM)

- **ESP32** con BLE (es. ESP32â€‘WROOM).  
- **Batteria LiPo** + interruttore.  
- **2 pulsanti** (scatto / funzione).  
- **Penna 3D** o corpo stampato.  
- **Cubo 3D** (stampa PLA/ABS) con sedi per **3â€“4 marker ArUco**.  
- **Camera**: webcam UVC o camera industriale (es. Basler) + illuminazione diffusa.  
- **Charuco o chessboard** per **calibrazione camera**.

---

## ğŸ§  Concetti chiave

### Marker & Posa
- Marker ArUco su un **cubo**: ogni faccia ospita un marker (almeno 3 visibili).  
- Dato lâ€™elenco di corner 2D â†” punti 3D noti, si usa `solvePnP` per ottenere **R, t** del cubo rispetto alla camera.

### Offset fino alla **punta**
- Misura/definisci una **trasformazione rigida** `T_cuboâ†’punta` (vettore offset 3D nel frame del cubo).  
- La posa della punta nel frame camera:  
  `p_punta_cam = R_cubo_cam * p_offset_cubo + t_cubo_cam`  
- Lâ€™orientamento della penna puÃ² essere definito da un asse del cubo o da 2â€“3 punti di riferimento.

### Sistemi di riferimento
- `camera_frame`: output primario.  
- `world_frame` (opzionale): fissa una board a vista; stima `T_cameraâ†’world` per trasformare la punta nel mondo.  
- `robot_frame` (futuro): nota `T_worldâ†’robot`, trasferisci la posa al braccio.

---

## ğŸ› ï¸ Software stack

- **Firmware ESP32 (Arduino/ESPâ€‘IDF)**: BLE GATT, gestione pulsanti, battery-awareness.  
- **PC App (Python)**:
  - **OpenCV** (ArUco, Charuco, solvePnP).
  - **Bleak** (BLE crossâ€‘platform).
  - **Acquisizione camera**: OpenCV/SDK vendor.
  - CLI + opzione GUI minimale (in roadmap).

---

## ğŸ“¦ Struttura del repository

```
aru-pen-pose/
â”œâ”€ esp32/
â”‚  â”œâ”€ src/
â”‚  â””â”€ platformio.ini (o Arduino .ino)
â”œâ”€ pc/
â”‚  â”œâ”€ app/
â”‚  â”‚  â”œâ”€ main.py
â”‚  â”‚  â”œâ”€ ble_listener.py
â”‚  â”‚  â”œâ”€ camera.py
â”‚  â”‚  â”œâ”€ aruco_pose.py
â”‚  â”‚  â”œâ”€ tip_transform.yaml     # offset cuboâ†’punta
â”‚  â”‚  â””â”€ config.yaml
â”‚  â”œâ”€ calib/
â”‚  â”‚  â”œâ”€ charuco_dict.yaml
â”‚  â”‚  â”œâ”€ camera_intrinsics.yaml
â”‚  â”‚  â””â”€ camera_distortion.yaml
â”‚  â””â”€ requirements.txt
â”œâ”€ stl/
â”‚  â”œâ”€ cube_mount.stl
â”‚  â””â”€ pen_body.stl
â”œâ”€ docs/
â”‚  â”œâ”€ aruco_layout.pdf
â”‚  â””â”€ protocol_ble.md
â””â”€ README.md
```

---

## ğŸš€ Setup rapido

### 1) Firmware ESP32
- Apri `firmware/esp32/` (Arduino IDE o PlatformIO).  
- Configura **device name BLE** e UUID delle caratteristiche in `config.h`.  
- Carica sul dispositivo.  
- Pulsante `SCATTO` â†’ invia **notifica** BLE.

### 2) PC App (Python 3.10+)
```bash
cd pc
python -m venv .venv
source .venv/bin/activate   # Windows: .venv\Scripts\activate
pip install -r app/requirements.txt
```

### 3) Calibrazione camera
- Stampa una **Charuco** (consigliata) o chessboard.  
- Usa lo script (da fornire in `pc/app/`) per:
  - raccogliere immagini,
  - stimare **intrinseci** e **distorsioni** (`camera_intrinsics.yaml`, `camera_distortion.yaml`).

### 4) Definizione offset cuboâ†’punta
- Misura in CAD o empiricamente lâ€™offset 3D dal **frame del cubo** alla **punta**.  
- Salva in `tip_transform.yaml`, es.:
  ```yaml
  tip_offset_mm: [0.0, 15.2, -38.5]   # x,y,z nel frame del cubo
  ```

### 5) Avvio
```bash
python app/main.py   --ble-name ARU-PEN   --camera 0   --dict DICT_4X4_50   --marker-size-mm 20.0
```

---

## ğŸ”— Protocollo BLE (proposta)

- **Service UUID**: `12345678-0000-0000-0000-1234567890ab`  
- **Characteristic (Notify)**: `12345678-0000-0000-0000-1234567890ac`  
- **Payload (littleâ€‘endian)**:
  ```
  u8 event_type   # 0x01 = TRIGGER
  u32 tick_ms
  u8 battery_pct
  u8 button_id    # 1=SCATTO, 2=ALTRO
  ```
- Il PC sottoscrive la characteristic â†’ ad ogni notifica esegue `capture()`.

---

## ğŸ¯ Rilevamento ArUco & PnP

- **Dictionary**: `DICT_4X4_50` (default, configurabile).  
- **Dimensioni marker**: es. 20 mm (definisci esatto in `--marker-size-mm`).  
- **Punti 3D**: definisci i corner nel **frame del cubo** (per ogni faccia montata).  
- **solvePnP**: `cv::solvePnP(objectPoints, imagePoints, K, dist, R, t)`.  
- **Punta**: `p_punta = R * offset + t`.  
- **Output**: JSON su stdout o su socket:
  ```json
  {
    "ts": 1723545600.123,
    "tip_position_camera_mm": [x, y, z],
    "tip_orientation_Rvec": [rx, ry, rz],
    "visibility_markers": 3,
    "image_path": "captures/2025-08-13_17-22-10.png"
  }
  ```

---

## ğŸ§ª Test & Debug

- **ModalitÃ  test** senza BLE: `--test-mode` â†’ scatti manuali (tasto o timer).  
- **Overlay**: disegna assi, ID marker, reprojection error medio.  
- **Log**: CSV con posa e residui PnP.

---

## ğŸ¤– Integrazione robot (roadmap)

- Pubblica la posa su **ROS 2** o ZeroMQ.  
- Definisci `T_cameraâ†’world` (board fissa) e `T_worldâ†’robot`.  
- Implementa **filtro** (Kalman/EMA) e **rate limiter**.  
- Aggiungi **handâ€‘eye calibration** se la camera Ã¨ sul polso del robot.

---

## ğŸ“ Consigli meccanici

- Mantieni **rigide** le distanze cuboâ†”punta.  
- Allinea una faccia del cubo allâ€™asse della penna per ridurre ambiguitÃ .  
- Evita riflessi sui marker (stampa opaca / adesivi matte).

---

## ğŸ”’ Sicurezza & uso

- Evita puntamento verso occhi (punta): **DPI** se necessario.  
- Assicurati che il robot lavori in area sicura (interlock, eâ€‘stop).  
- Logga sempre gli errori di detection e i fallimenti PnP.

---

## ğŸ“œ Licenza

MIT (o altra a tua scelta). Inserisci il file `LICENSE`.

---

## ğŸ—ºï¸ Roadmap

- [ ] GUI minimale per preview e conferma scatto  
- [ ] Streaming posa a 30 FPS (modalitÃ  continua)  
- [ ] Autocalibrazione offset cuboâ†’punta da 3 pose note  
- [ ] Integrazione ROS 2 / MoveIt  
- [ ] Test multi-camera e fusion

---

## ğŸ¤ Contributi

PR e issue benvenuti. Apri una issue con:
- log, versione, OS, camera usata, foto esempio, file di calibrazione.
